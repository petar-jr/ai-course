{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alustetaan systeemi alkuun..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy textacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in ./lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: jinja2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: setuptools in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (59.6.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: language-data>=1.2 in ./lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: wrapt in ./lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-lg==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in ./lib/python3.10/site-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: setuptools in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (59.6.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: jinja2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: language-data>=1.2 in ./lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: click>=8.0.0 in ./lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in ./lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "Collecting fi-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fi_core_news_sm-3.7.0/fi_core_news_sm-3.7.0-py3-none-any.whl (14.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in ./lib/python3.10/site-packages (from fi-core-news-sm==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (24.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.12.3)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.8.2)\n",
      "Requirement already satisfied: setuptools in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (59.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (4.66.4)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: language-data>=1.2 in ./lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (13.7.1)\n",
      "Requirement already satisfied: click>=8.0.0 in ./lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (7.0.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: wrapt in ./lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fi-core-news-sm==3.7.0) (0.1.2)\n",
      "Installing collected packages: fi-core-news-sm\n",
      "Successfully installed fi-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fi_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "!{sys.executable} -m spacy download en_core_web_sm\n",
    "!{sys.executable} -m spacy download en_core_web_lg\n",
    "!{sys.executable} -m spacy download fi_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://spacy.io/usage/spacy-101\n",
    "# https://realpython.com/natural-language-processing-spacy-python/\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladataan en_core_web_lg -paketti. Tämän saa asennettua\n",
    "\n",
    "python3 -m spacy download en_core_web_sm\n",
    "python3 -m spacy download en_core_web_lg\n",
    "python3 -m spacy download fi_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP dobj X.X. False False\n",
      "startup startup NOUN NN ccomp xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Testataan simppelillä lauseella.\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "hassuttelua\n",
      "\n",
      "This this PRON DT advmod Xxxx True True\n",
      "better well ADV RBR advmod xxxx True False\n",
      "might might AUX MD aux xxxx True True\n",
      "be be AUX VB ROOT xx True True\n",
      "better well ADJ JJR acomp xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "betting bet VERB VBG pcomp xxxx True False\n",
      "that that SCONJ IN dobj xxxx True True\n",
      "that that PRON DT advmod xxxx True True\n",
      "better well ADV RBR advmod xxxx True False\n",
      "better well ADV RBR advmod xxxx True False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entäs hassuttelulla?\n",
    "print(\"------------------\")\n",
    "print (\"hassuttelua\")\n",
    "print(\"\")\n",
    "doc_funny = nlp(\"This better might be better at betting that that better better\")\n",
    "# Elikkä suomeksi \"Uhkapelaaja on parempi uhkapelaamaan kuin parempi uhkapelaaja\"\n",
    "# Lemmojen pitäisi olla bettereissä bet, good, bet, good, bet\n",
    "for token in doc_funny:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        token.shape_, token.is_alpha, token.is_stop)\n",
    "# Vaan meneekö oikein?\n",
    "# No ei tainnut mennä, voi ei.\n",
    "# Eipä mennyt sanasijaintikaan...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Mitkä ovat erisnimiä?\n",
      "\n",
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Palataan takaisin siihen alkuperäiseen Apple-lauseeseen...\n",
    "\n",
    "print (\"--------------------\")\n",
    "print(\"Mitkä ovat erisnimiä?\")\n",
    "print(\"\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Voidaan tulostaa, että miltä sanat \"näyttävät\" ja ovatko ne tunnettuja?\n",
      "\n",
      "dog True 75.254234 False\n",
      "mutt True 23.737406 False\n",
      "cat True 63.188496 False\n",
      "lion True 55.145737 False\n",
      "leopard True 31.221588 False\n",
      "banana True 31.620354 False\n",
      "afskfsd False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Kokeillaan sitten toisenlaista tilannetta - ovatko sanat samankaltaisia?\n",
    "\n",
    "catdog_tokens = nlp(\"dog mutt cat lion leopard banana afskfsd\")\n",
    "print (\"--------------------\")\n",
    "print(\"Voidaan tulostaa, että miltä sanat \\\"näyttävät\\\" ja ovatko ne tunnettuja?\")\n",
    "print(\"\")\n",
    "\n",
    "for token in catdog_tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Voidaan tulostaa, ovatko sanat lähellä toisiaan?\n",
      "\n",
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.6871286202797843\n",
      "salty fries <-> hamburgers 0.6901010870933533\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"--------------------\")\n",
    "print(\"Voidaan tulostaa, ovatko sanat lähellä toisiaan?\")\n",
    "print(\"\")\n",
    "\n",
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "# Similarity of two documents\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
    "# Similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "burgers = doc1[5]\n",
    "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Voidaan myös selvittää sanojen yleisyyttä.\n",
    "\n",
    "complete_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech company. He is\"\n",
    "    \" interested in learning Natural Language Processing.\"\n",
    "    \" There is a developer conference happening on 21 July\"\n",
    "    ' 2019 in London. It is titled \"Applications of Natural'\n",
    "    ' Language Processing\". There is a helpline number'\n",
    "    \" available at +44-1234567891. Gus is helping organize it.\"\n",
    "    \" He keeps organizing local Python meetups and several\"\n",
    "    \" internal talks at his workplace. Gus is also presenting\"\n",
    "    ' a talk. The talk will introduce the reader about \"Use'\n",
    "    ' cases of Natural Language Processing in Fintech\".'\n",
    "    \" Apart from his work, he is very passionate about music.\"\n",
    "    \" Gus is learning to play the Piano. He has enrolled\"\n",
    "    \" himself in the weekend batch of Great Piano Academy.\"\n",
    "    \" Great Piano Academy is situated in Mayfair or the City\"\n",
    "    \" of London and has world-class piano instructors.\"\n",
    ")\n",
    "complete_doc = nlp(complete_text)\n",
    "\n",
    "words = [\n",
    "    token.text\n",
    "    for token in complete_doc\n",
    "    if not token.is_stop and not token.is_punct\n",
    "]\n",
    "\n",
    "print(Counter(words).most_common(5))\n",
    "# Pitäisi tulla\n",
    "#[('Gus', 4), ('London', 3), ('Natural', 3), ('Language', 3), ('Processing', 3)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nyt lisätään Language jossain muodossa (languages), niin nähdääen että mitä tapahtuu.\n",
    "\n",
    "complete_text_2 = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech company. He is\"\n",
    "    \" interested in learning Natural Language Processing.\"\n",
    "    \" There is a developer conference happening on 21 July\"\n",
    "    ' 2019 in London. It is titled \"Applications of Natural'\n",
    "    ' Language Processing\". There is a helpline number'\n",
    "    \" available at +44-1234567891. Gus is helping organize it.\"\n",
    "    \" He keeps organizing local Python meetups and several\"\n",
    "    \" internal talks at his workplace. Gus is also presenting\"\n",
    "    ' a talk. The talk will introduce the reader about \"Use'\n",
    "    ' cases of Natural Language Processing in Fintech\".'\n",
    "    \" Apart from his work, he is very passionate about music.\"\n",
    "    \" Gus is learning to play the Piano. He has enrolled\"\n",
    "    \" himself in the weekend batch of Great Piano Academy.\"\n",
    "    \" Great Piano Academy is situated in Mayfair or the City\"\n",
    "    \" of London and has world-class piano instructors. Also Language languages.\"\n",
    ")\n",
    "complete_doc_2 = nlp(complete_text_2)\n",
    "# nollataan sanalista.\n",
    "words=[]\n",
    "words = [\n",
    "    token.text\n",
    "    for token in complete_doc_2\n",
    "    if not token.is_stop and not token.is_punct\n",
    "]\n",
    "\n",
    "print(Counter(words).most_common(5))\n",
    "# lisättiin language ja languages, joten languagen pitäsi kasvaa kahdella?\n",
    "#[('Language', 5), ('Gus', 4), ('London', 3), ('Natural', 3), ('Processing', 3)]\n",
    "#Hmmmm... miksi ei tullutkaan language 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Koeponnistetaan uudestaan, nyt lemmalla.\n",
    "print(\"\")\n",
    "print(\"-----------\")\n",
    "print (\"kokeillaan lemmoilla\")\n",
    "print(\"\")\n",
    "lemmat1 = [\n",
    "    token.lemma_\n",
    "    for token in complete_doc\n",
    "    if not token.is_stop and not token.is_punct\n",
    "]\n",
    "print(Counter(lemmat1).most_common(5))\n",
    "\n",
    "lemmat2 = [\n",
    "    token.lemma_\n",
    "    for token in complete_doc_2\n",
    "    if not token.is_stop and not token.is_punct\n",
    "]\n",
    "print(Counter(lemmat2).most_common(5))\n",
    "\n",
    "# Miksi ei toimi (vinkki iso alkukirjain...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\")\n",
    "print(\"-----------\")\n",
    "print (\"kokeillaan lemmoilla, nyt lowercasessa\")\n",
    "print(\"stripataan lemmat kanssa turhista merkeistä\")\n",
    "print(\"\")\n",
    "lemmat1 = [\n",
    "    token.lemma_.strip().lower()\n",
    "    for token in complete_doc\n",
    "    if not token.is_stop and not token.is_punct\n",
    "]\n",
    "print(Counter(lemmat1).most_common(5))\n",
    "\n",
    "lemmat2 = [\n",
    "    token.lemma_.strip().lower()\n",
    "    for token in complete_doc_2\n",
    "    if not token.is_stop and not token.is_punct\n",
    "]\n",
    "print(Counter(lemmat2).most_common(5))\n",
    "# ja näin saatiin viisi language-sanaa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Voidaan kaivaa myöskin nimiä etunimi+sukunimi-pareja esiin.\n",
    "\n",
    "\n",
    "about_text = (\n",
    "    \"Jimbo Jones likes to fish.\"\n",
    "    \"Jumbo Jones is his brother.\"\n",
    "    \"Jumbo brings the bait.\"\n",
    "    \"On the other side of the city four friends\"\n",
    "    \" are standing in an alleyway.\"\n",
    "    \"Their names are: Bank Bill, Bale Bribble, Beff Boomhauer\"\n",
    "    \" and Bill Bauterive.\"\n",
    "    \"+35840123123 is Jimbo's phone number.\"\n",
    ")\n",
    "about_doc = nlp(about_text)\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Määritetään pattern matcheri, jolla voidaan hakea määritelmän mukaisia asioita.\n",
    "# Tässä tapauksessa koko nimi.\n",
    "def extract_full_name(nlp_doc):\n",
    "    pattern = [{\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\"}]\n",
    "    matcher.add(\"FULL_NAME\", [pattern])\n",
    "    matches = matcher(nlp_doc)\n",
    "    for _, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        yield span.text\n",
    "\n",
    "\n",
    "for name in extract_full_name(about_doc) :\n",
    "    print (name)\n",
    "\n",
    "# Matchereilla voidaan hakea muitankin käyttäen ylläolevaa patterneja,\n",
    "# esim. puh.numeroita, s-postiosoitteita jne.\n",
    "# Onkos meillä jotain jännää tekstissä?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\")\n",
    "print(\"---------------\")\n",
    "print(\"Osaako se suomea? Myös, miten sanat liittyvät toisiinsa?\")\n",
    "print(\"lisää luettavaa aiheesta, jos kiinnostaa https://nlp.stanford.edu/software/dependencies_manual.pdf\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "nlp_fi = spacy.load(\"fi_core_news_sm\")\n",
    "piano_text = \"Unelias Pekka opettelee hiljaa punaisen pianon soittamista.\"\n",
    "piano_doc = nlp_fi(piano_text)\n",
    "for token in piano_doc:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "TOKEN: {token.text}\n",
    "=====\n",
    "{token.tag_ = }\n",
    "{token.head.text = }\n",
    "{token.dep_ = }\"\"\"\n",
    "    )\n",
    "#voidaan piirtää käppyrä, jos tahtoo\n",
    "#displacy.serve(piano_doc, style=\"dep\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"---------------\")\n",
    "print(\"Snips snaps sanoo sakset?\")\n",
    "print(\"\")\n",
    "\n",
    "# Entäs, saadaanko pilkottua tekstia jollakin tavalla?\n",
    "\n",
    "one_line_about_text = (\n",
    "    \"Gus Proto is a Python developer\"\n",
    "    \" currently working for a London-based Fintech company\"\n",
    ")\n",
    "one_line_about_doc = nlp(one_line_about_text)\n",
    "\n",
    "# Extract children of `developer`\n",
    "print([token.text for token in one_line_about_doc[5].children])\n",
    "\n",
    "\n",
    "# Extract previous neighboring node of `developer`\n",
    "print (one_line_about_doc[5].nbor(-1))\n",
    "\n",
    "\n",
    "# Extract next neighboring node of `developer`\n",
    "print (one_line_about_doc[5].nbor())\n",
    "\n",
    "\n",
    "# Extract all tokens on the left of `developer`\n",
    "print([token.text for token in one_line_about_doc[5].lefts])\n",
    "\n",
    "\n",
    "# Extract tokens on the right of `developer`\n",
    "print([token.text for token in one_line_about_doc[5].rights])\n",
    "\n",
    "\n",
    "# Print subtree of `developer`\n",
    "print (list(one_line_about_doc[5].subtree))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Joskus meitä kiinnostaa parsia tekstistä toisiinsa liittyviä osia\n",
    "\n",
    "print(\"\")\n",
    "print(\"---------------\")\n",
    "print(\"Erilaisia osia lauseesta...\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "conference_text = (\n",
    "    \"There is a developer conference happening on 21 July 2019 in London.\"\n",
    ")\n",
    "conference_doc = nlp(conference_text)\n",
    "\n",
    "# Extract Noun Phrases\n",
    "for chunk in conference_doc.noun_chunks:\n",
    "    print (chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Haetaan sitten vielä tekstistä kaikki verbifraasit.\n",
    "# Tarvitsee asentaa textacy\n",
    "#pip install textacy \n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"---------------\")\n",
    "print(\"Erilaisia verbifraaseja...\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "import textacy\n",
    "\n",
    "about_talk_text = (\n",
    "    \"The talk will introduce reader about use\"\n",
    "    \" cases of Natural Language Processing in\"\n",
    "    \" Fintech, making use of\"\n",
    "    \" interesting examples along the way.\"\n",
    ")\n",
    "\n",
    "patterns = [{\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}]\n",
    "about_talk_doc = textacy.make_spacy_doc(\n",
    "    about_talk_text, lang=\"en_core_web_sm\"\n",
    ")\n",
    "verb_phrases = textacy.extract.token_matches(\n",
    "    about_talk_doc, patterns=patterns\n",
    ")\n",
    "\n",
    "# Print all verb phrases\n",
    "for chunk in verb_phrases:\n",
    "    print(chunk.text)\n",
    "\n",
    "\n",
    "\n",
    "# Extract noun phrase to explain what nouns are involved\n",
    "for chunk in about_talk_doc.noun_chunks:\n",
    "    print (chunk)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tekstin käsittelyssä voidaan tehdä myös  \n",
    "\n",
    "\n",
    "# Voidaan piirtää käppyröitä tekstin sisällöstä. Ks. https://spacy.io/api/top-level#displacy_options\n",
    "#displacy.serve(doc, style=\"dep\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
